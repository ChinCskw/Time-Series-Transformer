{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import tensorflow as tf\n",
    "from pyarrow import parquet as pq\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/Train/sales_train_validation.csv')\n",
    "train = train.drop(['item_id','cat_id','store_id'],axis =1)\n",
    "# train = train.drop(['item_id','dept_id','cat_id','store_id','state_id'],axis =1)\n",
    "train.index = train.id\n",
    "train = train.drop('id',axis = 1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDate = list(map(lambda x: 'd_'+str(x),list(range(1913-200,1913))))\n",
    "test = train[['dept_id','state_id']+testDate]\n",
    "train = train.drop(testDate,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do\n",
    "# 1. Calendar event generator corresponding to certain date\n",
    "# 2. Sell Price generator corresponding to certain date\n",
    "# 4. Make tensorflow dataset\n",
    "\n",
    "class feature_engineering(object):\n",
    "    \n",
    "    def __init__ (self,df,dimList,encoder = LabelEncoder,encodeDict = None):\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._dimList = dimList\n",
    "        self.arr = df.drop(dimList,axis =1).values\n",
    "        self.indexList = df.index.tolist()\n",
    "        self._encoder = encoder\n",
    "        self.labelDict,self.encodeDict = self._pandas_to_categorical_encode(encodeDict)\n",
    "\n",
    "\n",
    "    def _rolling_window(self,a, window):\n",
    "        shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "        strides = a.strides + (a.strides[-1],)\n",
    "        return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "    def _get_time_tensor(self,arr,window_size):\n",
    "        tmp = self._rolling_window(arr,window_size+1)\n",
    "        Xtensor = tmp[:,:-1].reshape(-1,window_size,1)\n",
    "        Ytensor = tmp[:,-1].reshape(-1,1)\n",
    "        return (Xtensor,Ytensor)\n",
    "\n",
    "    def _tensor_factory(self,arr,window_size,categoryIx):\n",
    "        X,Ytensor = self._get_time_tensor(arr,window_size)\n",
    "        Xtensor = {}\n",
    "        for i in self.labelDict:\n",
    "            label = self.labelDict[i][categoryIx]\n",
    "            Xtensor[i] = self._label_shape_transform(label,Ytensor.shape)\n",
    "        Xtensor['sells'] = X\n",
    "        return (Xtensor,Ytensor)\n",
    "\n",
    "    def np_to_time_tensor_generator(self,windowSize):\n",
    "        if np.ndim(self.arr) > 1:\n",
    "            for ix,v in enumerate(self.arr):\n",
    "                yield self._tensor_factory(v,windowSize,ix)\n",
    "        else:\n",
    "            yield self._tensor_factory(self.arr,windowSize,0) \n",
    "\n",
    "    def _label_encode(self,arr,encoder):\n",
    "        if encoder is None:\n",
    "            encoder = self._encoder()\n",
    "            enc_arr = encoder.fit_transform(arr)\n",
    "        else:\n",
    "            enc_arr = encoder.transform(arr)\n",
    "        return enc_arr,encoder\n",
    "\n",
    "    def _pandas_to_categorical_encode(self,encodeDict):\n",
    "        if encodeDict is None:\n",
    "            encodeDict = {}\n",
    "        labelDict = {}\n",
    "        for i in self._dimList:\n",
    "            if i in encodeDict:\n",
    "                enc_arr,encoder = self._label_encode(self._df[i],encodeDict[i])\n",
    "            else:\n",
    "                enc_arr,encoder = self._label_encode(self._df[i],None)\n",
    "            encodeDict[i] = encoder\n",
    "            labelDict[i] = enc_arr\n",
    "        return labelDict,encodeDict\n",
    "\n",
    "    def _label_shape_transform(self,label,shape):\n",
    "        tmp = np.zeros(shape)\n",
    "        tmp += label\n",
    "        return tmp\n",
    "\n",
    "    def get_encoder_class(self,label):\n",
    "        return len(self.encodeDict[label].classes_)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = feature_engineering(train,['dept_id','state_id'])\n",
    "dept_id_class_num = fe.get_encoder_class('dept_id')\n",
    "state_id_class_num = fe.get_encoder_class('state_id')\n",
    "windowSize = 100\n",
    "\n",
    "cacheFile = '../Data/Train/cache/'+str(uuid.uuid4())\n",
    "train_univariate = tf.data.Dataset.from_generator(\n",
    "    fe.np_to_time_tensor_generator,\n",
    "    (\n",
    "        {'sells':tf.float32, 'dept_id':tf.int16,'state_id':tf.int16},\n",
    "        tf.float32\n",
    "    ),\n",
    "    output_shapes = (\n",
    "        {\n",
    "            'sells':tf.TensorShape([None,windowSize,1]),\n",
    "            'dept_id':tf.TensorShape([None,1]),\n",
    "            'state_id':tf.TensorShape([None,1])},\n",
    "        tf.TensorShape([None,1])\n",
    "        ),\n",
    "    args = [windowSize])\n",
    "train_univariate = train_univariate.prefetch(tf.data.experimental.AUTOTUNE).cache().repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge = feature_engineering(train,['dept_id','state_id'],encodeDict= fe.encodeDict)\n",
    "\n",
    "cacheFile = '../Data/Val/cache/'+str(uuid.uuid4())\n",
    "val_univariate = tf.data.Dataset.from_generator(\n",
    "    ge.np_to_time_tensor_generator,\n",
    "    (\n",
    "        {'sells':tf.float32, 'dept_id':tf.int16,'state_id':tf.int16},\n",
    "        tf.float32\n",
    "    ),\n",
    "    output_shapes = (\n",
    "        {\n",
    "            'sells':tf.TensorShape([None,windowSize,1]),\n",
    "            'dept_id':tf.TensorShape([None,1]),\n",
    "            'state_id':tf.TensorShape([None,1])},\n",
    "        tf.TensorShape([None,1])\n",
    "        ),\n",
    "    args = [windowSize])\n",
    "vals_univariate = val_univariate.prefetch(tf.data.experimental.AUTOTUNE).cache().repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sells_input = tf.keras.layers.Input(shape=(windowSize,1),name = 'sells')\n",
    "dept_id_input = tf.keras.layers.Input(shape=1,name = 'dept_id')\n",
    "state_id_input = tf.keras.layers.Input(shape=1,name = 'state_id')\n",
    "\n",
    "dept_embed = tf.keras.layers.Embedding(dept_id_class_num,3)(dept_id_input)\n",
    "dept_embed =tf.keras.layers.Flatten()(dept_embed)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(29)(sells_input)\n",
    "dense = tf.keras.layers.Concatenate()([lstm,dept_embed])\n",
    "dense = tf.keras.layers.Dense(10,'elu')(dense)\n",
    "dense = tf.keras.layers.Dense(1)(dense)\n",
    "simple_lstm_model = tf.keras.models.Model({'sells':sells_input,'dept_id':dept_id_input,'state_id':state_id_input},dense)\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 2000 steps, validate for 50 steps\nEpoch 1/3\n2000/2000 [==============================] - 213s 106ms/step - loss: 1.1326 - val_loss: 1.1073\nEpoch 2/3\n2000/2000 [==============================] - 204s 102ms/step - loss: 1.1003 - val_loss: 1.0917\nEpoch 3/3\n2000/2000 [==============================] - 205s 103ms/step - loss: 1.0855 - val_loss: 1.0775\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2023a227240>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "EVALUATION_INTERVAL = 2000\n",
    "EPOCHS = 3\n",
    "\n",
    "simple_lstm_model.fit(\n",
    "    train_univariate,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch= EVALUATION_INTERVAL,\n",
    "    validation_data=vals_univariate, \n",
    "    validation_steps=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}