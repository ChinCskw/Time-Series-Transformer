{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time_series_transform as tst\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "port = tst.Stock_Transformer.from_stock_engine_period(\n",
    "    symbols = ['GOOGL','NDAQ',\"GOLD\"],\n",
    "    period = '5y',\n",
    "    engine = 'yahoo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "strategy = ta.Strategy(\n",
    "    name= 'mystrategy',\n",
    "    ta=[\n",
    "        {\"kind\": \"ema\", \"length\": 50},\n",
    "        {\"kind\": \"ema\", \"length\": 7},\n",
    "        {\"kind\": \"ema\", \"length\": 20},\n",
    "        {\"kind\": \"bbands\", \"length\": 20},\n",
    "        {\"kind\": \"bbands\", \"length\": 50},\n",
    "        {\"kind\": \"bbands\", \"length\": 30},\n",
    "        {\"kind\": \"rsi\",\"prefix\":\"rsi\"},\n",
    "        {\"kind\": \"macd\", \"fast\": 8, \"slow\": 21},\n",
    "    ]\n",
    ")\n",
    "port = port.get_technial_indicator(strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget_list = ['Open','High','Low','Close','Volume','EMA_50','EMA_7',\n",
    "     'EMA_20','BBL_20_2.0','BBM_20_2.0','BBU_20_2.0','BBL_50_2.0',\n",
    "    'BBM_50_2.0',\n",
    "    'BBU_50_2.0',\n",
    "    'BBL_30_2.0',\n",
    "    'BBM_30_2.0',\n",
    "    'BBU_30_2.0',\n",
    "    'rsi_RSI_14',\n",
    "    'MACD_8_21_9',\n",
    "    'MACDh_8_21_9',\n",
    "    'MACDs_8_21_9']\n",
    "port = port.make_lag_sequence(\n",
    "    traget_list,\n",
    "    windowSize = 60,\n",
    "    lagNum = 1,\n",
    "    suffix = '_lag_'\n",
    ")\n",
    "port = port.make_lead_sequence(traget_list,5,1,'_lead_')\n",
    "port = port.dropna()\n",
    "for t in traget_list:\n",
    "    port = port.remove_feature(t)\n",
    "df = port.to_pandas(True)\n",
    "trans = tst.Time_Series_Transformer.from_pandas(df,'Date',None)\n",
    "lag_cols = df.columns[df.columns.str.contains('_lag_')]\n",
    "lead_cols = df.drop('Close_lead_5_GOOGL',axis =1).columns[df.drop('Close_lead_5_GOOGL',axis =1).columns.str.contains('_lead_')]\n",
    "trans = trans.make_stack_sequence(list(lag_cols),'Lag_data')\n",
    "for i in list(lead_cols):\n",
    "    trans = trans.remove_feature(i)\n",
    "for i in list(lag_cols):\n",
    "    trans = trans.remove_feature(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trans.to_pandas()\n",
    "test = df.tail(100)\n",
    "train = df.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(train['Lag_data'].tolist())\n",
    "trainY = np.array(train['Close_lead_5_GOOGL'].tolist(),dtype=np.float32)\n",
    "testX = np.array(test['Lag_data'].tolist())\n",
    "testY = np.array(test['Close_lead_5_GOOGL'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from time_series_transform import tfDataset_adopter as tda\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(63,60),name = \"Close_seq\")\n",
    "x = layers.LayerNormalization()(inputs)\n",
    "x = layers.LSTM(5)(x)\n",
    "# output = layers.Flatten(name=\"change\")(x)\n",
    "# x = layers.Dense(50, activation=\"relu\", name=\"dense_2\")(x)\n",
    "# outputs = layers.Dense(5, name=\"change\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.01),\n",
    "    loss = tf.keras.losses.Huber()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1022.1752 - val_loss: 1365.1305\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.9178 - val_loss: 1365.0347\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1021.8062 - val_loss: 1364.9741\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1021.7426 - val_loss: 1364.9399\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1021.6948 - val_loss: 1364.9113\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.6555 - val_loss: 1364.8795\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1021.6138 - val_loss: 1364.8365\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.5635 - val_loss: 1364.7778\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1021.5032 - val_loss: 1364.7098\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.4435 - val_loss: 1364.6531\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1021.3940 - val_loss: 1364.6122\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.3560 - val_loss: 1364.5829\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.3265 - val_loss: 1364.5597\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.3028 - val_loss: 1364.5409\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1021.2832 - val_loss: 1364.5254\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1021.2673 - val_loss: 1364.5132\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2554 - val_loss: 1364.5040\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2463 - val_loss: 1364.4967\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2393 - val_loss: 1364.4910\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2337 - val_loss: 1364.4862\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2291 - val_loss: 1364.4819\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1021.2253 - val_loss: 1364.4785\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2220 - val_loss: 1364.4760\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1021.2193 - val_loss: 1364.4735\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1021.2169 - val_loss: 1364.4712\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1021.2148 - val_loss: 1364.4692\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1021.2131 - val_loss: 1364.4677\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1021.2115 - val_loss: 1364.4662\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1021.2101 - val_loss: 1364.4648\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1021.2089 - val_loss: 1364.4639\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1021.2079 - val_loss: 1364.4626\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2068 - val_loss: 1364.4618\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1021.2060 - val_loss: 1364.4612\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2052 - val_loss: 1364.4603\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2045 - val_loss: 1364.4597\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2039 - val_loss: 1364.4591\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1021.2034 - val_loss: 1364.4585\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1021.2028 - val_loss: 1364.4579\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1021.2022 - val_loss: 1364.4574\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2018 - val_loss: 1364.4570\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1021.2015 - val_loss: 1364.4565\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2011 - val_loss: 1364.4563\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2009 - val_loss: 1364.4559\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2004 - val_loss: 1364.4557\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.2002 - val_loss: 1364.4553\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1021.2000 - val_loss: 1364.4551\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.1998 - val_loss: 1364.4547\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1021.1995 - val_loss: 1364.4547\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1021.1993 - val_loss: 1364.4545\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1021.1992 - val_loss: 1364.4543\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1021.1989 - val_loss: 1364.4542\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-98830d14ea3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1046\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs = 300,\n",
    "    batch_size =1046,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prd = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({\"prd\":prd[2],\"real\":testY[2]}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
