{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["import gc,uuid\n","import pandas as pd\n","import numpy as np\n","import pyarrow as pa\n","import tensorflow as tf\n","from pyarrow import parquet as pq\n","from collections import defaultdict\n","from sklearn.preprocessing import LabelEncoder\n","from matplotlib import pyplot as plt\n","import time_series_transform\n","from time_series_transform.time_series_transformer import Time_Series_Transformer\n","from time_series_transform.sequence_transfomer import *"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["CATEGORICAL_DIM = ['item_id','dept_id','cat_id','store_id','state_id']\n","WINDOW_SIZE = 10\n","TEST_RANGE = WINDOW_SIZE + 50\n","df = pd.read_csv('../Data/Train/sales_train_validation.csv')\n","df.index = df.id\n","df = df.drop('id',axis = 1)"],"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["testDate = list(map(lambda x: 'd_'+str(x),list(range(1913-TEST_RANGE,1914))))\n","trainDateDrop = []\n","test = df[CATEGORICAL_DIM+testDate]\n","train = df.drop(testDate+trainDateDrop,axis = 1)\n","train = train.sample(frac = 1)\n","SEQ_TRANSFORMER = []"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["fe = Time_Series_Transformer(train,['item_id','dept_id','cat_id','store_id','state_id'],seqTransformerList = SEQ_TRANSFORMER)\n","dept_id_class_num = fe.get_encoder_class('dept_id')\n","state_id_class_num = fe.get_encoder_class('state_id')\n","store_id_class_num = fe.get_encoder_class('store_id')\n","cat_id_class_num = fe.get_encoder_class('cat_id')\n","\n","\n","train_univariate,train_step = fe.get_tf_dataset(WINDOW_SIZE)\n","train_univariate = train_univariate.shuffle(buffer_size=10000).prefetch(2).repeat()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["ge = Time_Series_Transformer(test,['item_id','dept_id','cat_id','store_id','state_id'],encodeDict= fe.encodeDict,seqTransformerList = SEQ_TRANSFORMER)\n","\n","val_univariate,val_step = ge.get_tf_dataset(WINDOW_SIZE)\n","val_univariate = val_univariate.shuffle(buffer_size=10000).prefetch(2).repeat()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["sells_input = tf.keras.layers.Input(shape=(WINDOW_SIZE,1),name = 'time_series')\n","cat_id_input= tf.keras.layers.Input(shape=1,name = 'cat_id')\n","store_id_input= tf.keras.layers.Input(shape=1,name = 'store_id')\n","dept_id_input = tf.keras.layers.Input(shape=1,name = 'dept_id')\n","state_id_input = tf.keras.layers.Input(shape=1,name = 'state_id')\n","\n","\n","dept_id = tf.keras.layers.Embedding(dept_id_class_num,2)(dept_id_input)\n","dept_id =tf.keras.layers.Flatten()(dept_id)\n","\n","state_id = tf.keras.layers.Embedding(dept_id_class_num,2)(state_id_input)\n","state_id =tf.keras.layers.Flatten()(state_id)\n","\n","cat_id = tf.keras.layers.Embedding(cat_id_class_num,2)(cat_id_input)\n","cat_id =tf.keras.layers.Flatten()(cat_id)\n","\n","store_id = tf.keras.layers.Embedding(store_id_class_num,2)(store_id_input)\n","store_id =tf.keras.layers.Flatten()(store_id)\n","\n","lstm = tf.keras.layers.Masking(np.nan)(sells_input)\n","lstm = tf.keras.layers.GRU(5)(lstm)\n","\n","cate = tf.keras.layers.Concatenate()([lstm,cat_id,store_id,dept_id,state_id])\n","\n","dense = tf.keras.layers.Dense(1,'relu')(lstm)\n","lstm_embed = tf.keras.models.Model({\n","    'time_series':sells_input,\n","    'cat_id':cat_id_input,\n","    'dept_id':dept_id_input,\n","    'state_id':state_id_input,\n","    'store_id':store_id_input\n","},dense)\n","lstm_embed.compile(optimizer='adam', loss='mse',metrics = ['mae','mse'])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"}],"source":["tf.keras.utils.plot_model(lstm_embed,show_shapes=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["EVALUATION_INTERVAL = len(list(fe.np_to_time_tensor_generator(WINDOW_SIZE)))\n","validation_steps =  10 #len(list(ge.np_to_time_tensor_generator(WINDOW_SIZE)))\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Train for 30490 steps, validate for 10 steps\nEpoch 1/10\n 1471/30490 [>.............................] - ETA: 26:57 - loss: 15.3834 - mae: 1.0535 - mse: 15.3834"}],"source":["lstm_embed.fit(\n","    train_univariate,\n","    epochs=EPOCHS,\n","    steps_per_epoch= EVALUATION_INTERVAL,\n","    validation_data=val_univariate, \n","    validation_steps=validation_steps\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"celltoolbar":"Tags","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3-final"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}