{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import tensorflow as tf\n",
    "from pyarrow import parquet as pq\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/Train/sales_train_validation.csv')\n",
    "# train = train.drop(['item_id','dept_id','cat_id','store_id','state_id'],axis =1)\n",
    "train.index = train.id\n",
    "train = train.drop('id',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do\n",
    "# 1. Index -> label encode -> stacked into generator\n",
    "# 2. Calendar event generator corresponding to certain date\n",
    "# 3. Sell Price generator corresponding to certain date\n",
    "# 4. Multi-Feature stacked generator\n",
    "\n",
    "class feature_engineering(object):\n",
    "    def __init__ (self,df,dimList,encoder = LabelEncoder):\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._dimList = dimList\n",
    "        self.arr = df.drop(dimList,axis =1).values\n",
    "        self.indexList = df.index.tolist()\n",
    "        self._encoder = encoder\n",
    "        self.encodeDict = None\n",
    "\n",
    "    def _rolling_window(self,a, window):\n",
    "        shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "        strides = a.strides + (a.strides[-1],)\n",
    "        return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "    def _get_time_tensor(self,arr,window_size):\n",
    "        tmp = self._rolling_window(arr,window_size+1)\n",
    "        Xtensor = tmp[:,:-1]\n",
    "        Ytensor = tmp[:,-1]\n",
    "        return (Xtensor.reshape(-1,window_size,1),Ytensor.reshape(-1,1))\n",
    "\n",
    "    def np_to_time_tensor_generator(self,windowSize):\n",
    "        if np.ndim(self.arr) > 1:\n",
    "            for ix,v in enumerate(arr):\n",
    "                yield self._get_time_tensor(v,windowSize)\n",
    "        else:\n",
    "            yield self._get_time_tensor(self.arr,windowSize) \n",
    "\n",
    "    def _label_encode(self,arr):\n",
    "        encoder = self._encoder\n",
    "        enc_arr = encoder().fit_transform(arr)\n",
    "        return enc_arr,encoder\n",
    "\n",
    "    def pandas_to_categorical_encode(self):\n",
    "        encodeDict = {}\n",
    "        labelDict = {}\n",
    "        for i in self._dimList:\n",
    "            enc_arr,encoder = self._label_encode(self._df[i])\n",
    "            encodeDict[i] = encoder\n",
    "            labelDict[i] = enc_arr\n",
    "        self.encodeDict = encodeDict\n",
    "        return labelDict\n",
    "\n",
    "    def _get_item_id(self,fullIndex):\n",
    "        tmp = fullIndex.split('_')\n",
    "        return '_'.join(tmp[:3])\n",
    "\n",
    "    def _get_store_id(self,fullIndex):\n",
    "        tmp = fullIndex.split('_')\n",
    "        return '_'.join(tmp[3:5])\n",
    "\n",
    "    def _get_cate_info(self,fullIndex,cateInfoDir):\n",
    "        item_id = _get_item_id(fullIndex)\n",
    "        store_id = _get_store_id(fullIndex)\n",
    "        return pd.read_parquet(cateInfoDir,filters = [(\"item_id\",'=',str(item_id)),(\"store_id\",'=',str(store_id))])\n",
    "\n",
    "    def _get_events(self,calendar_dir,sdate,edate):\n",
    "        df = pd.read_csv(calendar_dir)\n",
    "        df['d_num'] = df.d.apply(lambda x: x.replace('d_','')).astype('int')\n",
    "        return df[df.d_num.apply(lambda x: x <= edate and x >= sdate)]\n",
    "\n",
    "    def _get_future_events(self,calendar_dir, sdate,duration):\n",
    "        edate = sdate+duration-1\n",
    "        return _get_events(calendar_dir,sdate,edate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'item_id': array([1437, 1438, 1439, ..., 1434, 1435, 1436]),\n 'dept_id': array([3, 3, 3, ..., 2, 2, 2]),\n 'cat_id': array([1, 1, 1, ..., 0, 0, 0]),\n 'store_id': array([0, 0, 0, ..., 9, 9, 9]),\n 'state_id': array([0, 0, 0, ..., 2, 2, 2])}"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "train.columns\n",
    "fe = feature_engineering(train,['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "fe.pandas_to_categorical_encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheFile = str(uuid.uuid4())\n",
    "train_univariate = tf.data.Dataset.from_generator(\n",
    "    np_to_time_tensor_generator,\n",
    "    (tf.float32,tf.float32),\n",
    "    output_shapes = (tf.TensorShape([None,100,1]),tf.TensorShape([None,1])),\n",
    "    args = (train.head(100).values,100))\n",
    "train_univariate = train_univariate.prefetch(tf.data.experimental.AUTOTUNE).cache(cacheFile).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(29, input_shape=(100,1)),\n",
    "    tf.keras.layers.Dense(10,'elu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 2000\n",
    "EPOCHS = 10\n",
    "\n",
    "simple_lstm_model.fit(\n",
    "    train_univariate,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch= EVALUATION_INTERVAL,\n",
    "    validation_data=train_univariate, \n",
    "    validation_steps=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}